


```{r, setup, include=FALSE}
library(tidyverse)
library(robotstxt)
library(rvest)
library(knitr)
library(janitor)
library(rtweet)
library(tidytext)
library(countrycode)
library(rworldmap)
library(viridis)
library(GGally)
library(plotly)
library(dplyr)
library(stringr)


library(leaflet)
library(gganimate)
library(lubridate)
library(maps)
library(ggthemes)

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code

```


#Downloading Data

```{r}

#Downloading data sets
starbucks <- read_csv("Data/starbucks.csv")
city_income <- read_csv("Data/kaggle_income.csv")
county_pop <- read_csv("Data/us_county.csv")
unemployment <- read_csv("Data/unemployment.csv")
starbucks_positive <- read_csv("Data/starbucks_positive.csv")
starbucks_negative <- read_csv("Data/starbucks_negative.csv")



```

#Displaying Starbucks Location:


```{r}

#World Map
worldmap <- getMap(resolution = "coarse")
plot(worldmap, bg = "lightblue", col = "black")
points(starbucks$Longitude, starbucks$Latitude, 
       col = "red", cex = .01)

#US locations; except Hawaii and Alaska
us_stars <- starbucks %>%
  filter(Country=="US") %>%
  rename(State=`State/Province`) %>%
  filter(State!="AK") %>%
  filter(State!="HI")
  
usa <- map_data(map = "state"
                       , region = ".")
usa_states <- usa %>%
  select(region, group) %>%
  group_by(region) %>%
  summarize(
    group=sum(group)/n()
  )

state_info <- data.frame(state_full = tolower(state.name)
                         , State = state.abb
                         , Region = state.region)

us_map_star <- us_stars %>%
  left_join(state_info, by = "State") %>%
  left_join(usa_states, by = c("state_full" = "region"))

us <- map_data(map = "state"
                       , region = ".") 

ggplot() +
  geom_polygon(data=us, aes(x=long, y=lat, group = group),color="blue", fill="white") +
  geom_point(data=us_map_star, aes(x = Longitude, y = Latitude, group=group), color="green") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(title="Locations of Starbucks") +
  theme(legend.position="bottom") +
  scale_fill_distiller(palette = "BuPu", direction = "horizantle")

```

#Map of US locations With Magnitude of Starbucks Locations

```{r}

library(tmap)

usa_states <- map_data(map = "state"
                       , region = ".")

city_star <- us_map_star %>%
  group_by(City) %>%
  summarize(
    Count = n()
  )

city_count_star <- us_map_star %>%
  left_join(city_star, by = "City") %>%
  mutate(Count = round(Count, 1))


ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_point(data=city_count_star, aes(x = Longitude, y = Latitude, group=group, size=Count, color=Count)) +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  theme_void() +
  labs(color = "Amount of Starbucks in Each City") +
  scale_size(guide = "none") +
  theme(legend.title = element_text(color = "green", size = 8),
        legend.text = element_text(color = "green", size = 8))



```


#Collecting and Mapping tweets

```{r}


path_in <- "Users/mattadams/Desktop/Sophomore Year 1st Semester/Data Science/Blog-LetsGetFiscal/Data"

key <- readLines("api_key_twitter.txt")
secret_key <- readLines("api_secret_key.txt")
bearer_token <- readLines("api_bearer_token.txt")
access_token <- readLines("access_token.txt")
secret_access_token <- readLines("secret_access_token.txt")

#setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)


data(stop_words)
https <- rbind(stop_words, c("https", "SMART"))
t.co <- rbind(https, c("t.co", "SMART"))
stop_words_2 <- t.co

nrc_lexicon <- get_sentiments("nrc")

tweets <- search_tweets("starbucks", n = 1, lang = "en") %>%
  select(status_id, text, location) %>%
  filter(!is.na(location))

tweet_locations <- tweets %>%
  separate(location, into = c("City", "State")
           , sep = ","
           , remove = FALSE) %>%
  select(status_id, text, State) %>%
  na.omit()
  
#Before I create the one word per row dataset, group_by location and id, then it will keep tweet ID variable in

tweet_words0 <- tweet_locations %>%
  group_by(status_id, State) %>%
  unnest_tokens(output = word, input = text) %>%
  ungroup()

tweet_words1 <- tweet_words0 %>%
  anti_join(stop_words_2, by="word")
  
tweet_words <- tweet_words1 %>%
  group_by(State) %>%
  summarize(
    Total_Words = n(), word=word, State=State, status_id = status_id
  )

positive <- nrc_lexicon %>%
  filter(sentiment=="positive")

negative <- nrc_lexicon %>%
  filter(sentiment=="negative")

tweet_positive <- tweet_words %>%
  inner_join(positive, by="word") 

tweet_negative <- tweet_words %>%
  inner_join(negative, by="word")

state_info <- data.frame(state_full = tolower(state.name)
                         , State.abb = state.abb
                         , State.name = state.name
                         , Region = state.region)

word_count <- tweet_words %>%
  select(State, Total_Words) %>%
  group_by(State) %>%
  summarize(
    N = n()
  )

starbucks_positive <- tweet_positive %>%
  mutate(State=str_trim(State)) %>%
  group_by(State) %>%
  summarize (
    positive.proportion = n()/(sum(Total_Words)/n())
  ) %>%
  inner_join(state_info, by= c("State"="State.abb")) %>%
  right_join(usa_states, by = c("state_full" = "region"))

#write_csv(starbucks_positive, "starbucks_positive.csv")
  
#Plotting negative across US
starbucks_negative <- tweet_negative %>%
  mutate(State=str_trim(State)) %>%
  group_by(State) %>%
  summarize (
    negative.proportion = n()/(sum(Total_Words)/n())
  ) %>%
  inner_join(state_info, by= c("State"="State.abb")) %>%
  right_join(usa_states, by = c("state_full" = "region"))

#write_csv(starbucks_negative, "starbucks_negative.csv")

starbucks_negative

#Plotting negative across US
ggplot(starbucks_negative, aes(x = long, y = lat, group = group
                      , fill = negative.proportion)) +
  scale_fill_viridis() +
  geom_polygon(color = "white") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of Negative Words in Tweets Per State",
       caption = "*Grey states have no tweet information") +
    theme(legend.title = element_text(color = "green", size = 8),
        legend.text = element_text(color = "green", size = 8))

#Plotting positive across US
ggplot(starbucks_positive, aes(x = long, y = lat, group = group
                      , fill = positive.proportion)) +
  scale_fill_viridis() +
  geom_polygon(color = "white") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of Positive Words in Tweets Per State",
       caption = "*Grey states have no tweet information") +
    theme(legend.title = element_text(color = "green", size = 8),
        legend.text = element_text(color = "green", size = 8))



```


#Clustering by Unemployment, Negative Consumer Sentiment, and Income of each state


```{r}

income_state <- city_income %>%
  group_by(State_Name, State_ab) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) %>%
  mutate(State = tolower(State_Name)) %>%
  select(State, `Avg. Income`, State_ab)

unemployment_state <- unemployment %>%
  group_by(State) %>%
  na.omit() %>%
  summarize("Avg. Unemployment Rate" = mean(Rate, na.rm=TRUE)) %>%
  mutate(State = tolower(State))

starbucks_state <- starbucks %>%
  group_by(`State/Province`) %>%
  na.omit() %>%
  summarize("Num. Starbucks" = n())
  

star_neg <- starbucks_negative %>%
  select(negative.proportion, state_full) %>%
  group_by(state_full) %>%
  na.omit() %>%
  summarize(
    negative.proportion = mean(negative.proportion, na.rm=TRUE)
  )

star_pos <- starbucks_positive %>%
  select(positive.proportion, state_full) %>%
  group_by(state_full) %>%
  na.omit() %>%
  summarize(
    positive.proportion = mean(positive.proportion, na.rm=TRUE)
  )

state_factors <- income_state %>%
  left_join(unemployment_state, by="State") %>%
  left_join(star_neg, by = c("State"="state_full")) %>%
  left_join(star_pos, by = c("State"="state_full")) %>%
  left_join(starbucks_state, by = c("State_ab" = "State/Province"))

state_factors$`Avg. Unemployment Rate`[10] <- 7.6

final_state_factors <- state_factors %>%
  na.omit() %>%
  select(`Avg. Unemployment Rate`, `Avg. Income`, negative.proportion, `Num. Starbucks`)  %>%
  mutate(`Avg. Unemployment Rate` = as.numeric(`Avg. Unemployment Rate`)) %>%
  mutate(`Avg. Income` = as.numeric(`Avg. Income`)) %>%
  mutate(negative.proportion = as.numeric(negative.proportion)) %>%
  mutate(`Avg. Unemployment Rate` = round(`Avg. Unemployment Rate`, 3)) %>%
  mutate(`Avg. Income` = round(`Avg. Income`, 3)) %>%
  mutate(negative.proportion = round(negative.proportion, 3)) %>%
  ungroup()

final_final_state_factors <- final_state_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(`Avg. Unemployment Rate_std`, `Avg. Income_std`, negative.proportion_std, `Num. Starbucks_std`)

not_std <- final_state_factors %>%
  select(`Avg. Unemployment Rate`,`Avg. Income`, negative.proportion, `Num. Starbucks`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
km_out_std <- kmeans(final_final_state_factors, centers = 5, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=10, ncol=2)

#Collecting information for each cluster 
for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(final_final_state_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))


# add cluster assignments to the data frame
clust_3_std <- final_state_factors %>%
  mutate(clust3_std = as.character(km_out_std$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(State_Name=tolower(State_Name))

usa_states <- map_data(map = "state"
                       , region = ".")

final_cluster <- clust_3_std %>%
  left_join(usa_states, by = c("State_Name" = "region"))

ggplot() +
geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
geom_polygon(data=final_cluster, aes(x = long, y = lat, group = group, fill = clust3_std), color="black") +
  geom_polygon(color = "black") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "3 Clusters of Starbucks") +
  theme(legend.position="bottom")

vars_std = c("Avg. Unemployment Rate", "Avg. Income", "negative.proportion", "Num. Starbucks")

ggpairs(data = final_cluster
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

km_out_std$centers


```


#Finding centers of 5 clusters

```{r}

#Vermont
clust_1 <- final_state_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  mutate(clust3_std = as.character(km_out_std$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(State_Name=tolower(State_Name)) %>%
  filter(clust3_std==1) 

clust_1 <- clust_1 %>%
  mutate(dist = sqrt(
                      (`Avg. Unemployment Rate_std` - km_out_std$centers[2,1])^2 +
                      (`Avg. Income_std` - km_out_std$centers[2,2])^2 +
                      (`negative.proportion_std` - km_out_std$centers[2,3])^2 +
                      (`Num. Starbucks_std` - km_out_std$centers[2,3])^2)
  ) %>%
  arrange(dist)

#Virginia
clust_2 <- final_state_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  mutate(clust3_std = as.character(km_out_std$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(State_Name=tolower(State_Name)) %>%
  filter(clust3_std==2) 

clust_2 <- clust_2 %>%
  mutate(dist = sqrt(
                      (`Avg. Unemployment Rate_std` - km_out_std$centers[2,1])^2 +
                      (`Avg. Income_std` - km_out_std$centers[2,2])^2 +
                      (`negative.proportion_std` - km_out_std$centers[2,3])^2 +
                      (`Num. Starbucks_std` - km_out_std$centers[2,3])^2)
  ) %>%
  arrange(dist)

#Nevada
clust_3 <- final_state_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  mutate(clust3_std = as.character(km_out_std$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(State_Name=tolower(State_Name)) %>%
  filter(clust3_std==3) 

clust_3 <- clust_3 %>%
  mutate(dist = sqrt(
                      (`Avg. Unemployment Rate_std` - km_out_std$centers[2,1])^2 +
                      (`Avg. Income_std` - km_out_std$centers[2,2])^2 +
                      (`negative.proportion_std` - km_out_std$centers[2,3])^2 +
                      (`Num. Starbucks_std` - km_out_std$centers[2,3])^2)
  ) %>%
  arrange(dist)

#Wisconsin
clust_4 <- final_state_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  mutate(clust3_std = as.character(km_out_std$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(State_Name=tolower(State_Name)) %>%
  filter(clust3_std==4) 

clust_4 <- clust_4 %>%
  mutate(dist = sqrt(
                      (`Avg. Unemployment Rate_std` - km_out_std$centers[2,1])^2 +
                      (`Avg. Income_std` - km_out_std$centers[2,2])^2 +
                      (`negative.proportion_std` - km_out_std$centers[2,3])^2 +
                      (`Num. Starbucks_std` - km_out_std$centers[2,3])^2)
  ) %>%
  arrange(dist)

#California
clust_5 <- final_state_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  mutate(clust3_std = as.character(km_out_std$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(State_Name=tolower(State_Name)) %>%
  filter(clust3_std==5) 

clust_5 <- clust_5 %>%
  mutate(dist = sqrt(
                      (`Avg. Unemployment Rate_std` - km_out_std$centers[2,1])^2 +
                      (`Avg. Income_std` - km_out_std$centers[2,2])^2 +
                      (`negative.proportion_std` - km_out_std$centers[2,3])^2 +
                      (`Num. Starbucks_std` - km_out_std$centers[2,3])^2)
  ) %>%
  arrange(dist)

```


#Virginia: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

unemployment_county <- unemployment %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>%
  group_by(County) %>%
  na.omit() %>%
  summarize("Avg. Unemployment Rate" = mean(Rate, na.rm=TRUE)) 

va_income_city <- city_income %>%
  filter(State_Name=="Virginia") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

va_starbucks_city <- starbucks %>%
  filter(`State/Province`=="VA") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

va_city_info <- va_income_city %>%
  left_join(va_starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

va_county_info <- city_income %>%
  filter(State_ab=="VA") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(va_city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

va_county_factors <- va_county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

va_final_county <- va_county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
va_final_county_factors <- va_final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
va_county_km <- kmeans(va_final_county_factors, centers = 5, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=10, ncol=2)

#Collecting information for each cluster 
for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(va_final_county_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))

# add cluster assignments to the data frame
va_county_clust <- va_final_county %>%
  mutate(clust3_std = as.character(va_county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "virginia") %>%
  select(subregion, long, lat, group)

va_final_cluster <- va_county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=va_final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in Tennessee",
       caption = "*Grey states have no income or unemployment information",
       fill="Clusters") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = va_county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

va_poor_county <- va_county_clust %>%
  filter(clust3_std==4) %>%
  mutate(County=str_to_title(County)) %>%
  inner_join(va_county_factors, by="County") %>%
  select(County, `Avg. Income`, `Num. Starbucks`,`Avg. Unemployment Rate`)

#Cluster 4

```

#Vermont: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

vt_income_city <- city_income %>%
  filter(State_Name=="Vermont") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

vt_starbucks_city <- starbucks %>%
  filter(`State/Province`=="VT") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

vt_city_info <- vt_income_city %>%
  left_join(vt_starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

vt_county_info <- city_income %>%
  filter(State_ab=="VT") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(vt_city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

vt_county_factors <- vt_county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

vt_final_county <- vt_county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
vt_final_county_factors <- vt_final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
vt_county_km <- kmeans(vt_final_county_factors, centers = 4, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=7, ncol=2)

#Collecting information for each cluster 
for (i in 1:7){
  fig[i,1] <- i
  fig[i,2] <- kmeans(vt_final_county_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:7)) +
  labs(x = "K", y = expression("Total W"[k]))

# add cluster assignments to the data frame
vt_county_clust <- vt_final_county %>%
  mutate(clust3_std = as.character(vt_county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "vermont") %>%
  select(subregion, long, lat, group)

vt_final_cluster <- vt_county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=vt_final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in Tennessee",
       caption = "*Grey states have no income or unemployment information",
       fill="Clusters") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = vt_county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

vt_poor_county <- vt_county_clust %>%
  filter(clust3_std==1) %>%
  mutate(County=str_to_title(County)) %>%
  inner_join(vt_county_factors, by="County") %>%
  select(County, `Avg. Income`, `Num. Starbucks`,`Avg. Unemployment Rate`)

#Cluster 1

```


#Nevada: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

nv_income_city <- city_income %>%
  filter(State_Name=="Nevada") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

nv_starbucks_city <- starbucks %>%
  filter(`State/Province`=="NV") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

nv_city_info <- nv_income_city %>%
  left_join(nv_starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

nv_county_info <- city_income %>%
  filter(State_ab=="NV") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(nv_city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

nv_county_factors <- nv_county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

nv_final_county <- nv_county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
nv_final_county_factors <- nv_final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
nv_county_km <- kmeans(nv_final_county_factors, centers = 4, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=8, ncol=2)

#Collecting information for each cluster 
for (i in 1:8){
  fig[i,1] <- i
  fig[i,2] <- kmeans(nv_final_county_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:8)) +
  labs(x = "K", y = expression("Total W"[k]))

# add cluster assignments to the data frame
nv_county_clust <- nv_final_county %>%
  mutate(clust3_std = as.character(nv_county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "nevada") %>%
  select(subregion, long, lat, group)

nv_final_cluster <- nv_county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=nv_final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in Tennessee",
       caption = "*Grey states have no income or unemployment information") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = nv_county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

nv_poor_county <- nv_county_clust %>%
  filter(clust3_std==4) %>%
  mutate(County=str_to_title(County)) %>%
  inner_join(nv_county_factors, by="County") %>%
  select(County, `Avg. Income`, `Num. Starbucks`,`Avg. Unemployment Rate`)

#Cluster 4

```



#Wisconsin: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

wi_income_city <- city_income %>%
  filter(State_Name=="Wisconsin") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

wi_starbucks_city <- starbucks %>%
  filter(`State/Province`=="WI") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

wi_city_info <- wi_income_city %>%
  left_join(wi_starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

wi_county_info <- city_income %>%
  filter(State_ab=="WI") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(wi_city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

wi_county_factors <- wi_county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

wi_final_county <- wi_county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
wi_final_county_factors <- wi_final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
wi_county_km <- kmeans(wi_final_county_factors, centers = 5, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=10, ncol=2)

#Collecting information for each cluster 
for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(wi_final_county_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))


# add cluster assignments to the data frame
wi_county_clust <- wi_final_county %>%
  mutate(clust3_std = as.character(wi_county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "wisconsin") %>%
  select(subregion, long, lat, group)

wi_final_cluster <- wi_county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=wi_final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in California",
       caption = "*Grey states have no income or unemployment information") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = wi_county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

#Cluster 5
wi_poor_county <- wi_county_clust %>%
  filter(clust3_std==5) %>%
  mutate(County=str_to_title(County)) %>%
  inner_join(wi_county_factors, by="County") %>%
  select(County, `Avg. Income`, `Num. Starbucks`,`Avg. Unemployment Rate`)


```



#California: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

ca_income_city <- city_income %>%
  filter(State_Name=="California") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

ca_starbucks_city <- starbucks %>%
  filter(`State/Province`=="CA") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

ca_city_info <- ca_income_city %>%
  left_join(ca_starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

ca_county_info <- city_income %>%
  filter(State_ab=="CA") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(ca_city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

ca_county_factors <- ca_county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

ca_final_county <- ca_county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
ca_final_county_factors <- ca_final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
ca_county_km <- kmeans(ca_final_county_factors, centers = 4, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=10, ncol=2)

#Collecting information for each cluster 
for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(ca_final_county_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))


# add cluster assignments to the data frame
ca_county_clust <- ca_final_county %>%
  mutate(clust3_std = as.character(ca_county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "california") %>%
  select(subregion, long, lat, group)

ca_final_cluster <- ca_county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=ca_final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in California",
       caption = "*Grey states have no income or unemployment information") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = ca_county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

#Cluster 3
library(stringr)

ca_poor_county <- ca_county_clust %>%
  filter(clust3_std==1) %>%
  mutate(County=str_to_title(County)) %>%
  inner_join(ca_county_factors, by="County") %>%
  select(County, `Avg. Income`, `Num. Starbucks`,`Avg. Unemployment Rate`)


```

#Final County Recommendations 

```{r}

final_counties <- ca_poor_county %>%
  bind_rows(nv_poor_county) %>%
  bind_rows(vt_poor_county) %>%
  bind_rows(va_poor_county) %>%
  bind_rows(wi_poor_county) %>%
  filter(`Num. Starbucks`==0)

```



