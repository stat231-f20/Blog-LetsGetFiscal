


```{r, setup, include=FALSE}
library(tidyverse)
library(robotstxt)
library(rvest)
library(knitr)
library(janitor)
library(rtweet)
library(tidytext)
library(countrycode)
library(rworldmap)
library(viridis)
library(GGally)
library(plotly)
library(dplyr)

library(leaflet)
library(gganimate)
library(lubridate)
library(maps)
library(ggthemes)

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code

```


#Downloading Data

```{r}

#Downloading data sets
starbucks <- read_csv("Data/starbucks.csv")
city_income <- read_csv("Data/kaggle_income.csv")
county_pop <- read_csv("Data/us_county.csv")
unemployment <- read_csv("Data/unemployment.csv")
starbucks_positive <- read_csv("Data/starbucks_positive.csv")
starbucks_negative <- read_csv("Data/starbucks_negative.csv")



```

#Displaying Starbucks Location:


```{r}

#World Map
worldmap <- getMap(resolution = "coarse")
plot(worldmap, bg = "lightblue", col = "black")
points(starbucks$Longitude, starbucks$Latitude, 
       col = "red", cex = .01)

#US locations; except Hawaii and Alaska
us_stars <- starbucks %>%
  filter(Country=="US") %>%
  rename(State=`State/Province`) %>%
  filter(State!="AK") %>%
  filter(State!="HI")
  
usa <- map_data(map = "state"
                       , region = ".")
usa_states <- usa %>%
  select(region, group) %>%
  group_by(region) %>%
  summarize(
    group=sum(group)/n()
  )

state_info <- data.frame(state_full = tolower(state.name)
                         , State = state.abb
                         , Region = state.region)

us_map_star <- us_stars %>%
  left_join(state_info, by = "State") %>%
  left_join(usa_states, by = c("state_full" = "region"))

us <- map_data(map = "state"
                       , region = ".") 

ggplot() +
  geom_polygon(data=us, aes(x=long, y=lat, group = group),color="blue", fill="white") +
  geom_point(data=us_map_star, aes(x = Longitude, y = Latitude, group=group), color="green") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of colleges planning for in-person") +
  theme(legend.position="bottom") +
  scale_fill_distiller(palette = "BuPu", direction = "horizantle")

```

#Map of US locations With Magnitude of Starbucks Locations

```{r}

library(tmap)

usa_states <- map_data(map = "state"
                       , region = ".")

city_star <- us_map_star %>%
  group_by(City) %>%
  summarize(
    Count = n()
  )

city_count_star <- us_map_star %>%
  left_join(city_star, by = "City") 


ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_point(data=city_count_star, aes(x = Longitude, y = Latitude, group=group, size=Count, color=Count)) +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  theme_void() 



```


#Collecting and Mapping tweets

```{r}


path_in <- "Users/mattadams/Desktop/Sophomore Year 1st Semester/Data Science/Blog-LetsGetFiscal/Data"

key <- readLines("api_key_twitter.txt")
secret_key <- readLines("api_secret_key.txt")
bearer_token <- readLines("api_bearer_token.txt")
access_token <- readLines("access_token.txt")
secret_access_token <- readLines("secret_access_token.txt")

#setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)


data(stop_words)
https <- rbind(stop_words, c("https", "SMART"))
t.co <- rbind(https, c("t.co", "SMART"))
stop_words_2 <- t.co

nrc_lexicon <- get_sentiments("nrc")

tweets <- search_tweets("starbucks", n = 1, lang = "en") %>%
  select(status_id, text, location) %>%
  filter(!is.na(location))

tweet_locations <- tweets %>%
  separate(location, into = c("City", "State")
           , sep = ","
           , remove = FALSE) %>%
  select(status_id, text, State) %>%
  na.omit()
  
#Before I create the one word per row dataset, group_by location and id, then it will keep tweet ID variable in

tweet_words0 <- tweet_locations %>%
  group_by(status_id, State) %>%
  unnest_tokens(output = word, input = text) %>%
  ungroup()

tweet_words1 <- tweet_words0 %>%
  anti_join(stop_words_2, by="word")
  
tweet_words <- tweet_words1 %>%
  group_by(State) %>%
  summarize(
    Total_Words = n(), word=word, State=State, status_id = status_id
  )

positive <- nrc_lexicon %>%
  filter(sentiment=="positive")

negative <- nrc_lexicon %>%
  filter(sentiment=="negative")

tweet_positive <- tweet_words %>%
  inner_join(positive, by="word") 

tweet_negative <- tweet_words %>%
  inner_join(negative, by="word")

state_info <- data.frame(state_full = tolower(state.name)
                         , State.abb = state.abb
                         , State.name = state.name
                         , Region = state.region)

word_count <- tweet_words %>%
  select(State, Total_Words) %>%
  group_by(State) %>%
  summarize(
    N = n()
  )

starbucks_positive <- tweet_positive %>%
  mutate(State=str_trim(State)) %>%
  group_by(State) %>%
  summarize (
    positive.proportion = n()/(sum(Total_Words)/n())
  ) %>%
  inner_join(state_info, by= c("State"="State.abb")) %>%
  right_join(usa_states, by = c("state_full" = "region"))

#write_csv(starbucks_positive, "starbucks_positive.csv")

#Plotting positive across US
ggplot(starbucks_positive, aes(x = long, y = lat, group = group
                      , fill = positive.proportion)) +
  scale_fill_viridis() +
  geom_polygon(color = "white") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of Positive Words in Tweets Per State",
       caption = "*Grey states have no tweet information") +
  theme(legend.position="bottom") 
  
#Plotting negative across US
starbucks_negative <- tweet_negative %>%
  mutate(State=str_trim(State)) %>%
  group_by(State) %>%
  summarize (
    negative.proportion = n()/(sum(Total_Words)/n())
  ) %>%
  inner_join(state_info, by= c("State"="State.abb")) %>%
  right_join(usa_states, by = c("state_full" = "region"))

#write_csv(starbucks_negative, "starbucks_negative.csv")

starbucks_negative

ggplot(starbucks_negative, aes(x = long, y = lat, group = group
                      , fill = negative.proportion)) +
  scale_fill_viridis() +
  geom_polygon(color = "white") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of Negative Words in Tweets Per State",
       caption = "*Grey states have no tweet information") +
  theme(legend.position="bottom") 
  




```


#Clustering by Unemployment, Negative Consumer Sentiment, and Income of each state


```{r}

income_state <- city_income %>%
  group_by(State_Name, State_ab) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) %>%
  mutate(State = tolower(State_Name)) %>%
  select(State, `Avg. Income`, State_ab)

unemployment_state <- unemployment %>%
  group_by(State) %>%
  na.omit() %>%
  summarize("Avg. Unemployment Rate" = mean(Rate, na.rm=TRUE)) %>%
  mutate(State = tolower(State))

starbucks_state <- starbucks %>%
  group_by(`State/Province`) %>%
  na.omit() %>%
  summarize("Num. Starbucks" = n())
  

star_neg <- starbucks_negative %>%
  select(negative.proportion, state_full) %>%
  group_by(state_full) %>%
  na.omit() %>%
  summarize(
    negative.proportion = mean(negative.proportion, na.rm=TRUE)
  )

star_pos <- starbucks_positive %>%
  select(positive.proportion, state_full) %>%
  group_by(state_full) %>%
  na.omit() %>%
  summarize(
    positive.proportion = mean(positive.proportion, na.rm=TRUE)
  )

state_factors <- income_state %>%
  left_join(unemployment_state, by="State") %>%
  left_join(star_neg, by = c("State"="state_full")) %>%
  left_join(star_pos, by = c("State"="state_full")) %>%
  left_join(starbucks_state, by = c("State_ab" = "State/Province"))

state_factors$`Avg. Unemployment Rate`[10] <- 7.6

final_state_factors <- state_factors %>%
  na.omit() %>%
  select(`Avg. Unemployment Rate`, `Avg. Income`, negative.proportion, `Num. Starbucks`)  %>%
  mutate(`Avg. Unemployment Rate` = as.numeric(`Avg. Unemployment Rate`)) %>%
  mutate(`Avg. Income` = as.numeric(`Avg. Income`)) %>%
  mutate(negative.proportion = as.numeric(negative.proportion)) %>%
  mutate(`Avg. Unemployment Rate` = round(`Avg. Unemployment Rate`, 3)) %>%
  mutate(`Avg. Income` = round(`Avg. Income`, 3)) %>%
  mutate(negative.proportion = round(negative.proportion, 3)) %>%
  ungroup()

final_final_state_factors <- final_state_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(`Avg. Unemployment Rate_std`, `Avg. Income_std`, negative.proportion_std, `Num. Starbucks_std`)

not_std <- final_state_factors %>%
  select(`Avg. Unemployment Rate`,`Avg. Income`, negative.proportion, `Num. Starbucks`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
km_out_std <- kmeans(final_final_state_factors, centers = 3, nstart = 20)

km_not_std <- kmeans(not_std, centers = 3, nstart = 20)


# add cluster assignments to the data frame
clust_3_std <- final_state_factors %>%
  mutate(clust3_std = as.character(km_out_std$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(State_Name=tolower(State_Name))

clust_3 <- final_state_factors %>%
  mutate(clust3_not_std = as.character(km_not_std$cluster)) %>%
  arrange(clust3_not_std) %>%
  mutate(State_Name=tolower(State_Name))


usa_states <- map_data(map = "state"
                       , region = ".")

final_cluster <- clust_3_std %>%
  left_join(usa_states, by = c("State_Name" = "region"))

ggplot(final_cluster, aes(x = long, y = lat, group = group
                      , fill = clust3_std)) +
  geom_polygon(color = "black") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "3 Clusters of Starbucks") +
  theme(legend.position="bottom")

names <- unemployment

vars_std = c("Avg. Unemployment Rate", "Avg. Income", "negative.proportion", "Num. Starbucks")

ggpairs(data = final_cluster
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

km_out_std$centers

#Arizona
state_unemployment <- clust_3_std %>%
  filter(clust3_std==3) %>%
  arrange(desc(`Avg. Unemployment Rate`))

#mississippi
state_income <- clust_3_std %>%
  filter(clust3_std==3) %>%
  arrange((`Avg. Income`))

#maine
state_prop <- clust_3_std %>%
  filter(clust3_std==3) %>%
  arrange((`negative.proportion`))

#Blue cluster for the win

```


#Tennessee: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

income_city <- city_income %>%
  filter(State_Name=="Tennessee") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

starbucks_city <- starbucks %>%
  filter(`State/Province`=="TN") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

city_info <- income_city %>%
  left_join(starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

county_info <- city_income %>%
  filter(State_ab=="TN") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

unemployment_county <- unemployment %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>%
  group_by(County) %>%
  na.omit() %>%
  summarize("Avg. Unemployment Rate" = mean(Rate, na.rm=TRUE)) 

county_factors <- county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

final_county <- county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
final_county_factors <- final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
county_km <- kmeans(final_county_factors, centers = 3, nstart = 20)


# add cluster assignments to the data frame
county_clust <- final_county %>%
  mutate(clust3_std = as.character(county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "tennessee") %>%
  select(subregion, long, lat, group)

final_cluster <- county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in Tennessee",
       caption = "*Grey states have no income or unemployment information") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

#Blue cluster for the win

```




#Tennessee: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

income_city <- city_income %>%
  filter(State_Name=="Tennessee") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

starbucks_city <- starbucks %>%
  filter(`State/Province`=="TN") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

city_info <- income_city %>%
  left_join(starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

county_info <- city_income %>%
  filter(State_ab=="TN") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

unemployment_county <- unemployment %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>%
  group_by(County) %>%
  na.omit() %>%
  summarize("Avg. Unemployment Rate" = mean(Rate, na.rm=TRUE)) 

county_factors <- county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

final_county <- county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
final_county_factors <- final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
county_km <- kmeans(final_county_factors, centers = 3, nstart = 20)


# add cluster assignments to the data frame
county_clust <- final_county %>%
  mutate(clust3_std = as.character(county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "tennessee") %>%
  select(subregion, long, lat, group)

final_cluster <- county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in Tennessee",
       caption = "*Grey states have no income or unemployment information") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

#Blue cluster for the win

```



#California: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

income_city <- city_income %>%
  filter(State_Name=="California") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

starbucks_city <- starbucks %>%
  filter(`State/Province`=="CA") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

city_info <- income_city %>%
  left_join(starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

county_info <- city_income %>%
  filter(State_ab=="CA") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

unemployment_county <- unemployment %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>%
  group_by(County) %>%
  na.omit() %>%
  summarize("Avg. Unemployment Rate" = mean(Rate, na.rm=TRUE)) 

county_factors <- county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

final_county <- county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
final_county_factors <- final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
county_km <- kmeans(final_county_factors, centers = 3, nstart = 20)

# add cluster assignments to the data frame
county_clust <- final_county %>%
  mutate(clust3_std = as.character(county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "california") %>%
  select(subregion, long, lat, group)

final_cluster <- county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in California",
       caption = "*Grey states have no income or unemployment information") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))


```


#State-wide population 

```{r}

clean_county <- county_pop %>%
  separate(county, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>%
  separate(County, into = c("County", "Blank")
           , sep = "Census Area"
           , remove = FALSE) %>%
  select(County, state_code, population, long, lat) %>%
  mutate(County=tolower(County)) %>%
  mutate(County=str_trim(County))

state_pop <- clean_county %>%
  group_by(state_code) %>%
  summarize(
    pop = sum(population)
  )
  
usa_states <- map_data(map = "state"
                       , region = ".")

#usa_states <- usa_states0 %>%
 # group_by(subregion) %>%
 # summarize(
  #  group = mean(group)
  #) %>%
  #mutate(subregion=str_trim(subregion))


state_info <- data.frame(state_full = tolower(state.name)
                         , State = state.abb
                         , Region = state.region)

#WHY DOES IT ALWAYS INCREASE ROWS
#HOW CAN I FIX VISUALIZATION
county_population <- state_pop %>%
  left_join(state_info, by= c("state_code"="State")) %>%
  left_join(usa_states, by = c("state_full" = "region"))

ggplot() +
  geom_polygon(data=county_population, aes(x = long, y = lat, group=group, fill=population)) +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of colleges planning for in-person") +
  theme(legend.position="bottom") +
  scale_fill_distiller(palette = "BuPu", direction = "horizantle")


```


#Fast Food Chains Per Population (Creating a Fast Food Chain Density Metric)

```{r}

restaurants_us <- restaurants %>%
  filter(country == "US")

#Adding states to restaurants locations
city <- data.frame(city = us.cities) 
  
us_cities <- city %>%
  separate(city.name, into = c("city", "State")
           , sep = " "
           , remove = FALSE) 

rest_city <- restaurants_us %>%
  left_join(us_cities, by = "city") %>%
  rename(lat=latitude, long=longitude)

#Sum of Amount of Fast Food Chains in a city
fast_food_density <- rest_city %>%
  mutate(`Amount of Fast Food`=1) %>%
  group_by(State) %>%
  summarize(
    fast_density = sum(`Amount of Fast Food`)
  ) %>%
  na.omit

usa_states <- map_data(map = "state"
                       , region = ".")

state_info <- data.frame(state_full = tolower(state.name)
                         , State = state.abb
                         , Region = state.region)

restaurant_density_map <- fast_food_density %>%
  left_join(state_info, by = "State") %>%
  left_join(usa_states, by = c("state_full" = "region"))



ggplot(restaurant_density_map, aes(x = long, y = lat, group = group
                      , fill = fast_density)) +
  geom_polygon(color = "white") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of colleges planning for in-person") +
  theme(legend.position="bottom") 
  


```



