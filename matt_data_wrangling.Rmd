


```{r, setup, include=FALSE}
library(tidyverse)
library(robotstxt)
library(rvest)
library(knitr)
library(janitor)
library(rtweet)
library(tidytext)
library(countrycode)
library(rworldmap)
library(viridis)
library(GGally)
library(plotly)
library(dplyr)

library(leaflet)
library(gganimate)
library(lubridate)
library(maps)
library(ggthemes)

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code

```


#Downloading Data

```{r}

#Downloading data sets
starbucks <- read_csv("Data/starbucks.csv")
city_income <- read_csv("Data/kaggle_income.csv")
county_pop <- read_csv("Data/us_county.csv")
unemployment <- read_csv("Data/unemployment.csv")
starbucks_positive <- read_csv("Data/starbucks_positive.csv")
starbucks_negative <- read_csv("Data/starbucks_negative.csv")



```

#Displaying Starbucks Location:


```{r}

#World Map
worldmap <- getMap(resolution = "coarse")
plot(worldmap, bg = "lightblue", col = "black")
points(starbucks$Longitude, starbucks$Latitude, 
       col = "red", cex = .01)

#US locations; except Hawaii and Alaska
us_stars <- starbucks %>%
  filter(Country=="US") %>%
  rename(State=`State/Province`) %>%
  filter(State!="AK") %>%
  filter(State!="HI")
  
usa <- map_data(map = "state"
                       , region = ".")
usa_states <- usa %>%
  select(region, group) %>%
  group_by(region) %>%
  summarize(
    group=sum(group)/n()
  )

state_info <- data.frame(state_full = tolower(state.name)
                         , State = state.abb
                         , Region = state.region)

us_map_star <- us_stars %>%
  left_join(state_info, by = "State") %>%
  left_join(usa_states, by = c("state_full" = "region"))

us <- map_data(map = "state"
                       , region = ".") 

ggplot() +
  geom_polygon(data=us, aes(x=long, y=lat, group = group),color="blue", fill="white") +
  geom_point(data=us_map_star, aes(x = Longitude, y = Latitude, group=group), color="green") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of colleges planning for in-person") +
  theme(legend.position="bottom") +
  scale_fill_distiller(palette = "BuPu", direction = "horizantle")

```

#Map of US locations With Magnitude of Starbucks Locations

```{r}

library(tmap)

usa_states <- map_data(map = "state"
                       , region = ".")

city_star <- us_map_star %>%
  group_by(City) %>%
  summarize(
    Count = n()
  )

city_count_star <- us_map_star %>%
  left_join(city_star, by = "City") %>%
  mutate(Count = round(Count, 1))


ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_point(data=city_count_star, aes(x = Longitude, y = Latitude, group=group, size=Count, color=Count)) +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  theme_void() +
  labs(size = "Amount of Starbucks in Each City") +
  scale_size(guide = "none")



```


#Collecting and Mapping tweets

```{r}


path_in <- "Users/mattadams/Desktop/Sophomore Year 1st Semester/Data Science/Blog-LetsGetFiscal/Data"

key <- readLines("api_key_twitter.txt")
secret_key <- readLines("api_secret_key.txt")
bearer_token <- readLines("api_bearer_token.txt")
access_token <- readLines("access_token.txt")
secret_access_token <- readLines("secret_access_token.txt")

#setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)


data(stop_words)
https <- rbind(stop_words, c("https", "SMART"))
t.co <- rbind(https, c("t.co", "SMART"))
stop_words_2 <- t.co

nrc_lexicon <- get_sentiments("nrc")

tweets <- search_tweets("starbucks", n = 1, lang = "en") %>%
  select(status_id, text, location) %>%
  filter(!is.na(location))

tweet_locations <- tweets %>%
  separate(location, into = c("City", "State")
           , sep = ","
           , remove = FALSE) %>%
  select(status_id, text, State) %>%
  na.omit()
  
#Before I create the one word per row dataset, group_by location and id, then it will keep tweet ID variable in

tweet_words0 <- tweet_locations %>%
  group_by(status_id, State) %>%
  unnest_tokens(output = word, input = text) %>%
  ungroup()

tweet_words1 <- tweet_words0 %>%
  anti_join(stop_words_2, by="word")
  
tweet_words <- tweet_words1 %>%
  group_by(State) %>%
  summarize(
    Total_Words = n(), word=word, State=State, status_id = status_id
  )

positive <- nrc_lexicon %>%
  filter(sentiment=="positive")

negative <- nrc_lexicon %>%
  filter(sentiment=="negative")

tweet_positive <- tweet_words %>%
  inner_join(positive, by="word") 

tweet_negative <- tweet_words %>%
  inner_join(negative, by="word")

state_info <- data.frame(state_full = tolower(state.name)
                         , State.abb = state.abb
                         , State.name = state.name
                         , Region = state.region)

word_count <- tweet_words %>%
  select(State, Total_Words) %>%
  group_by(State) %>%
  summarize(
    N = n()
  )

starbucks_positive <- tweet_positive %>%
  mutate(State=str_trim(State)) %>%
  group_by(State) %>%
  summarize (
    positive.proportion = n()/(sum(Total_Words)/n())
  ) %>%
  inner_join(state_info, by= c("State"="State.abb")) %>%
  right_join(usa_states, by = c("state_full" = "region"))

#write_csv(starbucks_positive, "starbucks_positive.csv")
  
#Plotting negative across US
starbucks_negative <- tweet_negative %>%
  mutate(State=str_trim(State)) %>%
  group_by(State) %>%
  summarize (
    negative.proportion = n()/(sum(Total_Words)/n())
  ) %>%
  inner_join(state_info, by= c("State"="State.abb")) %>%
  right_join(usa_states, by = c("state_full" = "region"))

#write_csv(starbucks_negative, "starbucks_negative.csv")

starbucks_negative

#Plotting negative across US
ggplot(starbucks_negative, aes(x = long, y = lat, group = group
                      , fill = negative.proportion)) +
  scale_fill_viridis() +
  geom_polygon(color = "white") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of Negative Words in Tweets Per State",
       caption = "*Grey states have no tweet information")

#Plotting positive across US
ggplot(starbucks_positive, aes(x = long, y = lat, group = group
                      , fill = positive.proportion)) +
  scale_fill_viridis() +
  geom_polygon(color = "white") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "Proportion of Positive Words in Tweets Per State",
       caption = "*Grey states have no tweet information")



```


#Clustering by Unemployment, Negative Consumer Sentiment, and Income of each state


```{r}

income_state <- city_income %>%
  group_by(State_Name, State_ab) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) %>%
  mutate(State = tolower(State_Name)) %>%
  select(State, `Avg. Income`, State_ab)

unemployment_state <- unemployment %>%
  group_by(State) %>%
  na.omit() %>%
  summarize("Avg. Unemployment Rate" = mean(Rate, na.rm=TRUE)) %>%
  mutate(State = tolower(State))

starbucks_state <- starbucks %>%
  group_by(`State/Province`) %>%
  na.omit() %>%
  summarize("Num. Starbucks" = n())
  

star_neg <- starbucks_negative %>%
  select(negative.proportion, state_full) %>%
  group_by(state_full) %>%
  na.omit() %>%
  summarize(
    negative.proportion = mean(negative.proportion, na.rm=TRUE)
  )

star_pos <- starbucks_positive %>%
  select(positive.proportion, state_full) %>%
  group_by(state_full) %>%
  na.omit() %>%
  summarize(
    positive.proportion = mean(positive.proportion, na.rm=TRUE)
  )

state_factors <- income_state %>%
  left_join(unemployment_state, by="State") %>%
  left_join(star_neg, by = c("State"="state_full")) %>%
  left_join(star_pos, by = c("State"="state_full")) %>%
  left_join(starbucks_state, by = c("State_ab" = "State/Province"))

state_factors$`Avg. Unemployment Rate`[10] <- 7.6

final_state_factors <- state_factors %>%
  na.omit() %>%
  select(`Avg. Unemployment Rate`, `Avg. Income`, negative.proportion, `Num. Starbucks`)  %>%
  mutate(`Avg. Unemployment Rate` = as.numeric(`Avg. Unemployment Rate`)) %>%
  mutate(`Avg. Income` = as.numeric(`Avg. Income`)) %>%
  mutate(negative.proportion = as.numeric(negative.proportion)) %>%
  mutate(`Avg. Unemployment Rate` = round(`Avg. Unemployment Rate`, 3)) %>%
  mutate(`Avg. Income` = round(`Avg. Income`, 3)) %>%
  mutate(negative.proportion = round(negative.proportion, 3)) %>%
  ungroup()

final_final_state_factors <- final_state_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(`Avg. Unemployment Rate_std`, `Avg. Income_std`, negative.proportion_std, `Num. Starbucks_std`)

not_std <- final_state_factors %>%
  select(`Avg. Unemployment Rate`,`Avg. Income`, negative.proportion, `Num. Starbucks`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
km_out_std <- kmeans(final_final_state_factors, centers = 5, nstart = 20)

km_not_std <- kmeans(not_std, centers = 3, nstart = 20)


set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=10, ncol=2)

#Collecting information for each cluster 
for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(final_final_state_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))


# add cluster assignments to the data frame
clust_3_std <- final_state_factors %>%
  mutate(clust3_std = as.character(km_out_std$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(State_Name=tolower(State_Name))

clust_3 <- final_state_factors %>%
  mutate(clust3_not_std = as.character(km_not_std$cluster)) %>%
  arrange(clust3_not_std) %>%
  mutate(State_Name=tolower(State_Name))


usa_states <- map_data(map = "state"
                       , region = ".")

final_cluster <- clust_3_std %>%
  left_join(usa_states, by = c("State_Name" = "region"))

ggplot() +
geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
geom_polygon(data=final_cluster, aes(x = long, y = lat, group = group, fill = clust3_std), color="black") +
  geom_polygon(color = "black") +
  theme_void() +
  coord_fixed(ratio = 1.3) +
  labs(fill = "3 Clusters of Starbucks") +
  theme(legend.position="bottom")

names <- unemployment

vars_std = c("Avg. Unemployment Rate", "Avg. Income", "negative.proportion", "Num. Starbucks")

ggpairs(data = final_cluster
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

km_out_std$centers

#Arizona
state_unemployment <- clust_3_std %>%
  filter(clust3_std==3) %>%
  arrange(desc(`Avg. Unemployment Rate`))

#mississippi
state_income <- clust_3_std %>%
  filter(clust3_std==3) %>%
  arrange((`Avg. Income`))

#maine
state_prop <- clust_3_std %>%
  filter(clust3_std==3) %>%
  arrange((`negative.proportion`))

#Blue cluster for the win

```


#Tennessee: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

unemployment_county <- unemployment %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>%
  group_by(County) %>%
  na.omit() %>%
  summarize("Avg. Unemployment Rate" = mean(Rate, na.rm=TRUE)) 

tn_income_city <- city_income %>%
  filter(State_Name=="Tennessee") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

tn_starbucks_city <- starbucks %>%
  filter(`State/Province`=="TN") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

tn_city_info <- tn_income_city %>%
  left_join(tn_starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

tn_county_info <- city_income %>%
  filter(State_ab=="TN") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(tn_city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

tn_county_factors <- tn_county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

tn_final_county <- tn_county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
tn_final_county_factors <- tn_final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
tn_county_km <- kmeans(tn_final_county_factors, centers = 4, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=10, ncol=2)

#Collecting information for each cluster 
for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(tn_final_county_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))

# add cluster assignments to the data frame
tn_county_clust <- tn_final_county %>%
  mutate(clust3_std = as.character(tn_county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "tennessee") %>%
  select(subregion, long, lat, group)

tn_final_cluster <- tn_county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=tn_final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in Tennessee",
       caption = "*Grey states have no income or unemployment information",
       fill="Clusters") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = tn_county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

tn_poor_county <- tn_county_clust %>%
  filter(clust3_std==4) %>%
  mutate(County=str_to_title(County)) %>%
  inner_join(tn_county_factors, by="County") %>%
  select(County, `Avg. Income`, `Num. Starbucks`,`Avg. Unemployment Rate`)

#Cluster 2

```




#Colorado: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

co_income_city <- city_income %>%
  filter(State_Name=="Colorado") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

co_starbucks_city <- starbucks %>%
  filter(`State/Province`=="CO") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

co_city_info <- co_income_city %>%
  left_join(co_starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

co_county_info <- city_income %>%
  filter(State_ab=="CO") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(co_city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

co_county_factors <- co_county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

co_final_county <- co_county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
co_final_county_factors <- co_final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
co_county_km <- kmeans(co_final_county_factors, centers = 5, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=10, ncol=2)

#Collecting information for each cluster 
for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(co_final_county_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))

# add cluster assignments to the data frame
co_county_clust <- co_final_county %>%
  mutate(clust3_std = as.character(co_county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "colorado") %>%
  select(subregion, long, lat, group)

co_final_cluster <- co_county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=co_final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in Tennessee",
       caption = "*Grey states have no income or unemployment information") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = co_county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

co_poor_county <- co_county_clust %>%
  filter(clust3_std==4) %>%
  mutate(County=str_to_title(County)) %>%
  inner_join(co_county_factors, by="County") %>%
  select(County, `Avg. Income`, `Num. Starbucks`,`Avg. Unemployment Rate`)

#Cluster 3

```



#California: Clustering by Unemployment, Starbucks density, and Income of each county

```{r}

ca_income_city <- city_income %>%
  filter(State_Name=="California") %>%
  group_by(City) %>%
  na.omit() %>%
  summarize("Avg. Income" = mean(Mean, na.rm=TRUE)) 

ca_starbucks_city <- starbucks %>%
  filter(`State/Province`=="CA") %>%
  group_by(`City`) %>%
  summarize("Num. Starbucks" = n())

ca_city_info <- ca_income_city %>%
  left_join(ca_starbucks_city, by = c("City")) %>%
  mutate_all(~replace(., is.na(.), 0))

ca_county_info <- city_income %>%
  filter(State_ab=="CA") %>%
  select(City, County) %>%
  separate(County, into = c("County", "Blank")
           , sep = "County"
           , remove = FALSE) %>% 
  distinct() %>%
  left_join(ca_city_info, by = c("City")) %>%
  group_by(County) %>%
  summarize(
    "Avg. Income" = mean(`Avg. Income`), 
    "Num. Starbucks" = sum(`Num. Starbucks`)
  )

ca_county_factors <- ca_county_info %>%
  left_join(unemployment_county, by = c("County")) %>%
  na.omit()

ca_final_county <- ca_county_factors %>%
  mutate_if(is.numeric, funs(`std`=scale(.) %>% as.vector())) %>%
  select(County, `Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)
  
ca_final_county_factors <- ca_final_county %>%
  select(`Avg. Income_std`, `Num. Starbucks_std`, `Avg. Unemployment Rate_std`)

# apply the k-means algorithm (set the seed to make the results reproducible)
set.seed(75)
ca_county_km <- kmeans(ca_final_county_factors, centers = 4, nstart = 20)

set.seed(75)
#Create a folder with 10 0s.
fig <- matrix(NA, nrow=10, ncol=2)

#Collecting information for each cluster 
for (i in 1:10){
  fig[i,1] <- i
  fig[i,2] <- kmeans(ca_final_county_factors, centers = i, nstart = 20)$tot.withinss
}

#Visualizing "Elbow Plot"
ggplot(data = as.data.frame(fig), aes(x = V1, y = V2)) +
  geom_point() + 
  geom_line() +
  scale_x_continuous(breaks=c(1:10)) +
  labs(x = "K", y = expression("Total W"[k]))


# add cluster assignments to the data frame
ca_county_clust <- ca_final_county %>%
  mutate(clust3_std = as.character(ca_county_km$cluster)) %>%
  arrange(clust3_std) %>%
  mutate(County=tolower(County))

usa_states <- map_data(map = "county"
                       , region = "california") %>%
  select(subregion, long, lat, group)

ca_final_cluster <- ca_county_clust %>%
  mutate(County=str_trim(County)) %>%
  left_join(usa_states, by = c("County" = "subregion"))

ggplot() +
  geom_polygon(data = usa_states, aes(x=long, y = lat, group = group), color="black", fill="black", alpha=0.3) +
  geom_polygon(data=ca_final_cluster, aes(x = long, y = lat, group=group, fill=clust3_std), color="black") +
  scale_size_continuous(range=c(1,12)) +
  scale_color_viridis(trans="log") +
  labs(title = "Clusters in California",
       caption = "*Grey states have no income or unemployment information") +
  theme_void()

vars_std = c("Avg. Income_std", "Num. Starbucks_std", "Avg. Unemployment Rate_std")

ggpairs(data = ca_county_clust
        , aes(color = clust3_std) 
        , columns = vars_std
        , upper = list(continuous = "blank"))

#Cluster 3
library(stringr)

ca_poor_county <- ca_county_clust %>%
  filter(clust3_std==1) %>%
  mutate(County=str_to_title(County)) %>%
  inner_join(ca_county_factors, by="County") %>%
  select(County, `Avg. Income`, `Num. Starbucks`,`Avg. Unemployment Rate`)


```


#Final County Recommendations 

```{r}

final_counties <- ca_poor_county %>%
  bind_rows(co_poor_county) %>%
  bind_rows(tn_poor_county)

```



